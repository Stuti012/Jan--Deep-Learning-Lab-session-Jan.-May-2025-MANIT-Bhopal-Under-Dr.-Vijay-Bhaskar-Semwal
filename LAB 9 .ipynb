{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a97106",
   "metadata": {},
   "source": [
    "## Q.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd01c4",
   "metadata": {},
   "source": [
    "#### 1: Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b1c57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# All uppercase letters\n",
    "alphabet = list(string.ascii_uppercase)\n",
    "char2idx = {ch: idx for idx, ch in enumerate(alphabet)}\n",
    "idx2char = {idx: ch for ch, idx in char2idx.items()}\n",
    "\n",
    "# Create sequences with missing values\n",
    "def create_sequence_data(seq_len=7, num_samples=1000):\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        start = np.random.randint(0, 26 - seq_len)\n",
    "        full_seq = alphabet[start:start+seq_len]\n",
    "        missing_idx = np.random.randint(1, seq_len-1)  # avoid first and last\n",
    "        target = full_seq[missing_idx]\n",
    "        input_seq = full_seq[:]\n",
    "        input_seq[missing_idx] = '_'\n",
    "        data.append((\"\".join(input_seq), target, missing_idx))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de448d",
   "metadata": {},
   "source": [
    "#### 2: Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57dbe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphabetDataset(Dataset):\n",
    "    def __init__(self, sequence_data):\n",
    "        self.data = sequence_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq, target, missing_idx = self.data[idx]\n",
    "        x = [char2idx[ch] if ch != '_' else 0 for ch in seq]  # placeholder\n",
    "        mask = [1 if ch == '_' else 0 for ch in seq]  # mask the missing one\n",
    "        y = char2idx[target]\n",
    "        return torch.tensor(x), torch.tensor(mask), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd882cac",
   "metadata": {},
   "source": [
    "#### 3: Build the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a80292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=16, hidden_dim=32):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        masked_out = out[torch.arange(x.size(0)), mask.argmax(dim=1)]\n",
    "        return self.fc(masked_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a75a7f",
   "metadata": {},
   "source": [
    "#### 4: Build the Bidirectional RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f612a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=16, hidden_dim=32):\n",
    "        super(BiRNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, vocab_size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        masked_out = out[torch.arange(x.size(0)), mask.argmax(dim=1)]\n",
    "        return self.fc(masked_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb387e7",
   "metadata": {},
   "source": [
    "####  5: Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a67a93bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5606\n",
      "Epoch 2, Loss: 0.0343\n",
      "Epoch 3, Loss: 0.0110\n",
      "Epoch 4, Loss: 0.0079\n",
      "Epoch 5, Loss: 0.0160\n",
      "Epoch 1, Loss: 0.0374\n",
      "Epoch 2, Loss: 0.0060\n",
      "Epoch 3, Loss: 0.0028\n",
      "Epoch 4, Loss: 0.0030\n",
      "Epoch 5, Loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "def train(model, dataloader, epochs=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    for epoch in range(epochs):\n",
    "        for x, mask, y in dataloader:\n",
    "            logits = model(x, mask)\n",
    "            loss = criterion(logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "# Prepare dataset\n",
    "data = create_sequence_data(num_samples=1000)\n",
    "dataset = AlphabetDataset(data)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Train RNN\n",
    "rnn_model = RNNModel(vocab_size=len(alphabet))\n",
    "train(rnn_model, loader)\n",
    "\n",
    "# Train Bi-RNN\n",
    "birnn_model = BiRNNModel(vocab_size=len(alphabet))\n",
    "train(birnn_model, loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8183cae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence: ['M', 'A', 'C', 'H', 'I', 'N', '_']\n",
      "RNN Prediction: O\n",
      "BiRNN Prediction: T\n"
     ]
    }
   ],
   "source": [
    "def predict_missing(model, seq):\n",
    "    x = [char2idx[ch] if ch != '_' else 0 for ch in seq]\n",
    "    mask = [1 if ch == '_' else 0 for ch in seq]\n",
    "    x_tensor = torch.tensor([x])\n",
    "    mask_tensor = torch.tensor([mask])\n",
    "    logits = model(x_tensor, mask_tensor)\n",
    "    pred_idx = torch.argmax(logits, dim=1).item()\n",
    "    return idx2char[pred_idx]\n",
    "\n",
    "test_seq = list(\"MACHINE\")\n",
    "test_seq[6] = '_'\n",
    "print(\"Input Sequence:\", test_seq)\n",
    "print(\"RNN Prediction:\", predict_missing(rnn_model, test_seq))\n",
    "print(\"BiRNN Prediction:\", predict_missing(birnn_model, test_seq))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eff3da",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c6b17a",
   "metadata": {},
   "source": [
    "#### 1: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ceeea88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'the': 1, 'cat': 2, 'sat': 3, 'on': 4, 'mat': 5, 'dog': 6, 'rug': 7, 'bird': 8, 'flew': 9, 'in': 10, 'sky': 11, 'jumped': 12, 'over': 13, 'fence': 14}\n",
      "Max Sequence Length: 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Sample dataset\n",
    "sentences = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"The dog sat on the rug\",\n",
    "    \"The bird flew in the sky\",\n",
    "    \"The cat jumped over the fence\"\n",
    "]\n",
    "\n",
    "# Tokenize sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "total_words = len(word_index) + 1  # for padding\n",
    "\n",
    "# Generate input sequences and labels\n",
    "input_sequences = []\n",
    "labels = []\n",
    "\n",
    "for line in sentences:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        input_sequences.append(token_list[:i])\n",
    "        labels.append(token_list[i])\n",
    "\n",
    "# Pad sequences\n",
    "max_seq_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre')\n",
    "\n",
    "# One-hot encode the labels\n",
    "labels = to_categorical(labels, num_classes=total_words)\n",
    "\n",
    "print(f\"Vocabulary: {word_index}\")\n",
    "print(f\"Max Sequence Length: {max_seq_len}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68787b25",
   "metadata": {},
   "source": [
    "#### 2: Build the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36ea200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 5, 10)             150       \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 64)                4800      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15)                975       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,925\n",
      "Trainable params: 5,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 10, input_length=max_seq_len))\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65647562",
   "metadata": {},
   "source": [
    "#### 3: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71016a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2110abeea10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_sequences, labels, epochs=200, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145cb0fa",
   "metadata": {},
   "source": [
    "#### 4: Predict the Next Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2397206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'The cat sat on' → Predicted next word: 'the'\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(text, tokenizer, model, max_seq_len):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_seq_len, padding='pre')\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted)\n",
    "    \n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            return word\n",
    "    return \"\"\n",
    "\n",
    "test_input = \"The cat sat on\"\n",
    "predicted_word = predict_next_word(test_input, tokenizer, model, max_seq_len)\n",
    "print(f\"Input: '{test_input}' → Predicted next word: '{predicted_word}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e327c5",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2720705",
   "metadata": {},
   "source": [
    "#### 1: Preprocess the Notes (Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daf69824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Mapping: {'ma': 1, 're': 2, 'ga': 3, 'pa': 4, 'sa': 5, 'dha': 6, 'ni': 7, 'sha': 8}\n"
     ]
    }
   ],
   "source": [
    "# Raga scale (e.g., a basic ascending/descending pattern)\n",
    "raga_notes = [\n",
    "    \"Sa Re Ga Ma Pa Dha Ni Sha\",\n",
    "    \"Sha Ni Dha Pa Ma Ga Re Sa\",\n",
    "    \"Sa Re Ga Ma Ga Re Sa\",\n",
    "    \"Ma Pa Dha Ni Sha Dha Pa Ma\",\n",
    "    \"Re Ga Ma Pa Ma Ga Re\"\n",
    "]\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(raga_notes)\n",
    "total_notes = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences\n",
    "input_seqs = []\n",
    "labels = []\n",
    "\n",
    "for line in raga_notes:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        input_seqs.append(token_list[:i])\n",
    "        labels.append(token_list[i])\n",
    "\n",
    "max_len = max(len(seq) for seq in input_seqs)\n",
    "input_seqs = pad_sequences(input_seqs, maxlen=max_len, padding='pre')\n",
    "labels = to_categorical(labels, num_classes=total_notes)\n",
    "\n",
    "print(\"Vocabulary Mapping:\", tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f98e33",
   "metadata": {},
   "source": [
    "#### 2: Build the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c706664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 7, 10)             90        \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 64)                4800      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9)                 585       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,475\n",
      "Trainable params: 5,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_notes, 10, input_length=max_len))\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(total_notes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1ecf5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2110b019ed0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_seqs, labels, epochs=500, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6ab085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_raga_sequence(seed_text, next_notes=10):\n",
    "    for _ in range(next_notes):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_len, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)\n",
    "        predicted_note_index = np.argmax(predicted_probs)\n",
    "        \n",
    "        for note, index in tokenizer.word_index.items():\n",
    "            if index == predicted_note_index:\n",
    "                seed_text += ' ' + note\n",
    "                break\n",
    "    return seed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d58ce641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Raga Sequence: Sa Re Ga ma ga re sa ma sa ma ga\n"
     ]
    }
   ],
   "source": [
    "seed = \"Sa Re Ga\"\n",
    "generated_sequence = generate_raga_sequence(seed, next_notes=8)\n",
    "print(\"Generated Raga Sequence:\", generated_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc48ac5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
